{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import raha\n",
    "import json\n",
    "import numpy\n",
    "import math\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(dd,lb,cf,mode,opt1,opt2,prop):\n",
    "    det = raha.detection.Detection()\n",
    "    d = det.initialize_dataset(dd)\n",
    "    if lb != 0: det.LABELING_BUDGET = lb\n",
    "    if cf != \"\": det.CLASSIFICATION_MODEL = cf\n",
    "    if mode != \"\": det.COMPARE_MODE = mode\n",
    "    if opt1 != \"\": det.COMPARE_SIMILARITY = opt1\n",
    "    if opt2 != \"\": det.COMPARE_DISTANCE = opt2\n",
    "    det.run_strategies(d)\n",
    "    det.generate_features(d)\n",
    "    det.build_clusters(d)\n",
    "    while len(d.labeled_tuples) < lb:\n",
    "        det.sample_tuple(d)\n",
    "        if d.has_ground_truth:\n",
    "            det.label_with_ground_truth(d)\n",
    "    if prop == \"normal\":\n",
    "        det.propagate_labels(d)\n",
    "        det.predict_labels(d)\n",
    "    if prop == \"test\":\n",
    "        det.propagate_weighted_labels7(d)\n",
    "        det.propagate_weighted_heterogene_labels4(d)\n",
    "        det.predict_weighted_labels2(d)\n",
    "    if prop == \"test1\":\n",
    "        det.propagate_weighted_labels8(d)\n",
    "        det.propagate_weighted_heterogene_labels6(d)\n",
    "        det.predict_weighted_labels2(d)\n",
    "    data = raha.dataset.Dataset(dd)\n",
    "    p, r, f = data.get_data_cleaning_evaluation(d.detected_cells)[:3]\n",
    "    print(\"Clusters:\",det.COUNT_CLUSTER)\n",
    "    print(\"Raha's performance on {}:\\nPrecision = {:.2f}\\nRecall = {:.2f}\\nF1 = {:.2f}\".format(data.name, p, r, f))\n",
    "    return d, p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cells = [(3,1),(3,2),(7,2),(8,1),(10,1),(11,2)]\n",
    "data_dict_1 = {\n",
    "    \"name\": \"hospital\",\n",
    "    \"path\": \"hospital_dirty.csv\",\n",
    "    \"clean_path\": \"hospital_clean.csv\"\n",
    "}\n",
    "data_dict_2 = {\n",
    "    \"name\": \"test\",\n",
    "    \"path\": \"dirty_test.csv\",\n",
    "    \"clean_path\": \"clean_test.csv\"\n",
    "}\n",
    "data_dict_3 = {\n",
    "    \"name\": \"flights\",\n",
    "    \"path\": \"flights_dirty.csv\",\n",
    "    \"clean_path\": \"flights_clean.csv\"\n",
    "}\n",
    "data_dict_4 = {\n",
    "    \"name\": \"movies\",\n",
    "    \"path\": \"movies_dirty.csv\",\n",
    "    \"clean_path\": \"movies_clean.csv\"\n",
    "}\n",
    "data_dict_5 = {\n",
    "    \"name\": \"rayyan\",\n",
    "    \"path\": \"rayyan_dirty.csv\",\n",
    "    \"clean_path\": \"rayyan_clean.csv\"\n",
    "}\n",
    "data_dict_6 = {\n",
    "    \"name\": \"toy\",\n",
    "    \"path\": \"toy_dirty.csv\",\n",
    "    \"clean_path\": \"toy_clean.csv\"\n",
    "}\n",
    "d_test,_,_,f = run_test(data_dict_1,20,\"GBC\",\"distance\",\"\",\"euclidean\",\"test1\")\n",
    "\n",
    "#print(d_test.labeled_cells_j_c)\n",
    "stats = [[],[],[]]\n",
    "# for i in range(0):\n",
    "#     _,p1,r1,f1 = run_test(data_dict_3,20,\"GBC\",\"\",\"distance\",\"euclidean\",\"test1\")\n",
    "#     _,p2,r2,f2 = run_test(data_dict_3,20,\"GBC\",\"\",\"distance\",\"euclidean\",\"test2\")\n",
    "#     _,p3,r3,f3 = run_test(data_dict_3,20,\"GBC\",\"\",\"\",\"\",\"normal\")\n",
    "#     stats[0].append(f1)\n",
    "#     stats[1].append(f2)\n",
    "#     stats[2].append(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(runs,dd):\n",
    "    det = raha.detection.Detection()\n",
    "    d = det.initialize_dataset(dd)\n",
    "    det.run_strategies(d)\n",
    "    det.generate_features(d)\n",
    "    \n",
    "    classifier = [\"GBC\"]\n",
    "    prop_config = [\"normal\",\"test\"]\n",
    "    prop_test = [\"test3\",\"test6\"]\n",
    "    dds = []\n",
    "    stats = []\n",
    "    clusters = []\n",
    "    \n",
    "    for r in range(runs):\n",
    "        print(\"Run:\",r)\n",
    "        det_tmp = copy.deepcopy(det)\n",
    "        d_tmp = copy.deepcopy(d)\n",
    "        det_tmp.build_clusters(d_tmp)\n",
    "        while len(d_tmp.labeled_tuples) < 20:\n",
    "            det_tmp.sample_tuple(d_tmp)\n",
    "            if d_tmp.has_ground_truth:\n",
    "                det_tmp.label_with_ground_truth(d_tmp)\n",
    "        for prop in prop_config:\n",
    "            if prop == \"normal\":\n",
    "                print(prop)\n",
    "                det_tmp_tmp = copy.deepcopy(det_tmp)\n",
    "                d_tmp_tmp = copy.deepcopy(d_tmp)\n",
    "                det_tmp_tmp.propagate_labels(d_tmp_tmp)\n",
    "                det_tmp_tmp.predict_labels(d_tmp_tmp)\n",
    "                data = raha.dataset.Dataset(dd)\n",
    "                p, r, f = data.get_data_cleaning_evaluation(d_tmp_tmp.detected_cells)[:3]\n",
    "                stats.append([p,r,f,(prop)])\n",
    "            if prop == \"test\":\n",
    "                for pr in prop_test:\n",
    "                    for cl in classifier:\n",
    "                        print(prop,pr,cl)\n",
    "                        det_tmp_tmp = copy.deepcopy(det_tmp)\n",
    "                        det_tmp_tmp.CLASSIFICATION_MODEL = cl\n",
    "                        d_tmp_tmp = copy.deepcopy(d_tmp)\n",
    "                        if pr == \"test0\": det_tmp_tmp.propagate_weighted_labels4(d_tmp_tmp) # like normal\n",
    "                        if pr == \"test1\": det_tmp_tmp.propagate_weighted_labels5(d_tmp_tmp) # distance to nearest labeled cells\n",
    "                        if pr == \"test2\": det_tmp_tmp.propagate_weighted_labels6(d_tmp_tmp) # only labeled cells\n",
    "                        if pr == \"test3\":\n",
    "                            det_tmp_tmp.propagate_weighted_labels7(d_tmp_tmp) # only dense cells around labbele cells\n",
    "                            clusters.append(det_tmp_tmp.COUNT_CLUSTER)\n",
    "                        if pr == \"test4\":\n",
    "                            det_tmp_tmp.LABEL_PROPAGATION_METHOD = \"heterogeneity\" # heterogene cells also. no dbscan in heterogene cluster\n",
    "                            det_tmp_tmp.propagate_weighted_labels7(d_tmp_tmp)\n",
    "                            det_tmp_tmp.propagate_weighted_heterogene_labels4(d_tmp_tmp)\n",
    "                        if pr == \"test5\":\n",
    "                            det_tmp_tmp.LABEL_PROPAGATION_METHOD = \"heterogeneity\" #  heterogene cells also. dbscan in heterogene cluster\n",
    "                            det_tmp_tmp.propagate_weighted_labels7(d_tmp_tmp)\n",
    "                            det_tmp_tmp.propagate_weighted_heterogene_labels5(d_tmp_tmp)\n",
    "                        if pr == \"test6\":\n",
    "                            det_tmp_tmp.propagate_weighted_labels8(d_tmp_tmp)\n",
    "                        det_tmp_tmp.predict_weighted_labels2(d_tmp_tmp)\n",
    "                        data = raha.dataset.Dataset(dd)\n",
    "                        p, r, f = data.get_data_cleaning_evaluation(d_tmp_tmp.detected_cells)[:3]\n",
    "                        stats.append([p,r,f,(prop,pr,cl)])\n",
    "    return stats,clusters\n",
    "st,cc = evaluate(20,data_dict_1)\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 20\n",
    "configs = 3\n",
    "clr = [\"y-\",\"r-\",\"b-\",\"g-\",\"y-\",\"y-\"]\n",
    "plt.figure(1)\n",
    "for config in range(configs):\n",
    "    x = [i for i in range(runs)]\n",
    "    y = [st[i*configs+config][2] for i in range(runs)]\n",
    "    plt.plot(x,y,clr[config])\n",
    "plt.show()\n",
    "for config in range(configs):\n",
    "    print(clr[config],st[config][3],sum([st[i*configs+config][2] for i in range(runs)])/runs)\n",
    "# print(\"y:\",st[0][0][3],sum([st[0][i*configs][2] for i in range(runs)]))\n",
    "# print(\"r:\",st[0][1][3],sum([st[0][i*configs+1][2] for i in range(runs)]))\n",
    "# print(\"b:\",st[0][2][3],sum([st[0][i*configs+2][2] for i in range(runs)]))\n",
    "# print(\"g:\",st[0][3][3],sum([st[0][i*configs+3][2] for i in range(runs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = copy.deepcopy(d_test)\n",
    "k = len(d.labeled_tuples) + 2 - 1\n",
    "for j in range(d.dataframe.shape[1]):\n",
    "    for c in d.clusters_k_j_c_ce[k][j]:\n",
    "        if (sum(d.labels_per_cluster[(j, c)].values()) not in [0, len(d.labels_per_cluster[(j, c)])]) and len(d.labels_per_cluster[(j, c)]) != 0:\n",
    "            x = [d.column_features[j][i] for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "            cells = [(i,j) for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "            for sub_cluster in range(20):\n",
    "                km = sklearn.cluster.KMeans(n_clusters=(sub_cluster+2)).fit(x)\n",
    "                sub_clusters = {sub_c: [] for sub_c in range(sub_cluster+2)}\n",
    "                labeled_sub_clusters = []\n",
    "                for i,cell in enumerate(cells):\n",
    "                    #print(cell,km.labels_[i])\n",
    "                    sub_clusters[km.labels_[i]].append(cell)\n",
    "                homogene = True\n",
    "                for sub_c in sub_clusters:\n",
    "                    sub_labeled = {}\n",
    "                    for cell in sub_clusters[sub_c]:\n",
    "                        if cell in d.labeled_cells_j_c[j][c][0]: sub_labeled[cell] = d.labeled_cells_j_c[j][c][0][cell][1]\n",
    "                    if len(sub_labeled) != 0 and sum(sub_labeled.values()) not in [0,len(sub_labeled.values())]: homogene = False\n",
    "                if homogene:\n",
    "                    sub_cluster_number = set()\n",
    "                    for cell in d.labeled_cells_j_c[j][c][0]:\n",
    "                        for sub_c in sub_clusters:\n",
    "                            if cell in sub_clusters[sub_c]:sub_cluster_number.add((sub_c,d.labeled_cells_j_c[j][c][0][cell][1]))\n",
    "                    print(sub_cluster_number)\n",
    "                    \n",
    "                    for n in sub_cluster_number:\n",
    "                        sub_c = n[0]\n",
    "                        x_tmp = [x[i] for i,cell in enumerate(cells) if cell in sub_clusters[sub_c]]\n",
    "                        cells_tmp = [cell for cell in cells if cell in sub_clusters[sub_c]]\n",
    "                        if len(x_tmp) > 1:\n",
    "                            nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=2).fit(x)\n",
    "                            distances, indices = nbrs.kneighbors(x)\n",
    "                            distances = numpy.sort(distances, axis=0)[:,1]\n",
    "                            #calc if slope is over 1% between two distances then choose value as eps\n",
    "                            eps = distances[0]\n",
    "                            v1 = 0\n",
    "                            for x1 in range(len(distances)-1):\n",
    "                                v2 = distances[x1+1]-distances[x1]\n",
    "                                if 100*v2 > 101*v1:\n",
    "                                    eps = distances[x1+1]\n",
    "                                    break\n",
    "                                v1 = v2\n",
    "                            label = n[1]\n",
    "                            if eps == 0:\n",
    "                                for cell in sub_clusters[sub_c]:\n",
    "                                    if cell in d.labeled_cells_j_c[j][c][1]: d.labeled_cells_j_c[j][c][1][cell] = (1.0,label)\n",
    "                            else:\n",
    "                                db = sklearn.cluster.DBSCAN(eps=eps).fit(x_tmp)\n",
    "                                db_cluster = []\n",
    "                                closest_dist = {}\n",
    "                                for i,cell in enumerate(cells_tmp):\n",
    "                                    if cell in d.labeled_cells_j_c[j][c][0] and db.labels_[i] != -1:\n",
    "                                        db_cluster.append(db.labels_[i])\n",
    "                                for i,cell in enumerate(cells_tmp):\n",
    "                                    if db.labels_[i] in db_cluster and cell in d.labeled_cells_j_c[j][c][1]:\n",
    "                                        x_cell = x[cells.index(cell)]\n",
    "                                        max_dist = 0\n",
    "                                        for cell2 in d.labeled_cells_j_c[j][c][0]:\n",
    "                                            x_cell2 = x[cells.index(cell2)]\n",
    "                                            dist = get_distance(x_cell,x_cell2,\"euclidean\")\n",
    "                                            if dist > max_dist: max_dist = dist\n",
    "                                        d.labeled_cells_j_c[j][c][1][cell] = (1-max_dist,label)\n",
    "                                print(d.labeled_cells_j_c[j][c])\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(vec1,vec2,config):\n",
    "    #collect 2x2 0/0,0/1,1/0,1/1\n",
    "    tbl = [0]*4\n",
    "    for i in range(len(vec1)):\n",
    "        if vec1[i] == 1 and vec2[i] == 1: tbl[0] += 1\n",
    "        if vec1[i] == 1 and vec2[i] == 0: tbl[1] += 1\n",
    "        if vec1[i] == 0 and vec2[i] == 1: tbl[2] += 1\n",
    "        if vec1[i] == 0 and vec2[i] == 0: tbl[3] += 1\n",
    "    if config == \"matching\":\n",
    "        sim_coeff = (tbl[0]+tbl[3])/sum(tbl)\n",
    "    if config == \"jaccard\":\n",
    "        sim_coeff = tbl[0]/(tbl[0]+tbl[1]+tbl[2])\n",
    "    if config == \"dice\":\n",
    "        sim_coeff = 2*tbl[0]/(2*tbl[0]+tbl[1]+tbl[2])\n",
    "    if config == \"antidice\":\n",
    "        sim_coeff = tbl[0]/(tbl[0]+2*tbl[1]+2*tbl[2])\n",
    "    if config == \"sneath\":\n",
    "        sim_coeff = (2*tbl[0]+2*tbl[3])/(2*tbl[0]+tbl[1]+tbl[2]+2*tbl[3])\n",
    "    if config == \"rogers\":\n",
    "        sim_coeff = (tbl[0]+tbl[3])/(tbl[0]+2*tbl[1]+2*tbl[2]+tbl[3])\n",
    "    return sim_coeff\n",
    "\n",
    "def get_distance(vec1,vec2,config):    \n",
    "    if config == \"euclidean\":\n",
    "        dist = numpy.linalg.norm(numpy.subtract(vec1,vec2),ord=2) / numpy.linalg.norm(numpy.ones(len(vec1)))\n",
    "    if config == \"hamming\":\n",
    "        dist = numpy.linalg.norm(numpy.subtract(vec1,vec2),ord=1) / len(vec1)\n",
    "    if config == \"normal\":\n",
    "        dist = numpy.linalg.norm(numpy.subtract(vec1,vec2),ord=2)\n",
    "    if config == \"cosine\":\n",
    "        if sum(vec1) == 0 or sum(vec2) == 0: dist = 0\n",
    "        else: dist = numpy.dot(vec1,vec2)/(numpy.linalg.norm(vec1)*numpy.linalg.norm(vec2))\n",
    "    if config == \"dot\":\n",
    "        dist = numpy.dot(vec1,vec2)/len(vec1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance([1,1],[1,1],\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_weigthed_labels2(d):\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    labeled_cells_j_c = {j: {c: [{},{}] for c in range(k)} for j in range(d.dataframe.shape[1])}\n",
    "    # index 0 = labeled, 1 = unlabeled\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in d.clusters_k_j_c_ce[k][j]:\n",
    "            for cell in d.clusters_k_j_c_ce[k][j][c]:\n",
    "                if cell in d.labeled_cells:\n",
    "                    labeled_cells_j_c[j][c][0][cell] = d.labeled_cells[cell][0]\n",
    "                else:\n",
    "                    labeled_cells_j_c[j][c][1][cell] = (1,1) #weight,label\n",
    "            #homogene\n",
    "            if (sum(labeled_cells_j_c[j][c][0].values()) in [0,len(labeled_cells_j_c[j][c][0].values())]) and (len(labeled_cells_j_c[j][c][0].values()) != 0):\n",
    "                sub_cluster_train = [d.column_features[j][i] for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "                sub_cluster_cells = [(i,j) for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "                sub_cluster_labels = []\n",
    "                for i in range(d.dataframe.shape[0]):\n",
    "                    if (i,j) in labeled_cells_j_c[j][c][0]:\n",
    "                        sub_cluster_labels.append(labeled_cells_j_c[j][c][0][(i,j)])\n",
    "                    elif (i,j) in labeled_cells_j_c[j][c][1]:\n",
    "                        sub_cluster_labels.append(-1)\n",
    "                label_prop = LabelPropagation().fit(sub_cluster_train,sub_cluster_labels)\n",
    "                for i in range(len(sub_cluster_train)):\n",
    "                    if sub_cluster_cells[i] in labeled_cells_j_c[j][c][1]: labeled_cells_j_c[j][c][1][sub_cluster_cells[i]] = (max(label_prop.label_distributions_[i]),label_prop.transduction_[i])\n",
    "    return labeled_cells_j_c\n",
    "lc = propagate_weigthed_labels2(d_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(d):\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    labeled_cells_j_c = {j: {c: [{},{}] for c in range(k)} for j in range(d.dataframe.shape[1])}\n",
    "    # index 0 = labeled, 1 = unlabeled\n",
    "    print(d.labeled_tuples)\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in d.clusters_k_j_c_ce[k][j]:\n",
    "            #print(c,d.clusters_k_j_c_ce[k][j][c])\n",
    "            for cell in d.clusters_k_j_c_ce[k][j][c]:\n",
    "                #print(cell)\n",
    "                if cell in d.labeled_cells:\n",
    "                    labeled_cells_j_c[j][c][0][cell] = (1,d.labeled_cells[cell][0])\n",
    "                else:\n",
    "                    labeled_cells_j_c[j][c][1][cell] = (1,1) #weight,label to fit weight and y_train to ai\n",
    "            #homogene\n",
    "            if (sum(d.labels_per_cluster[(j, c)].values()) in [0, len(d.labels_per_cluster[(j, c)])]) and len(d.labels_per_cluster[(j, c)]) != 0:\n",
    "                label = list(d.labels_per_cluster[(j, c)].values())[0]\n",
    "                for cell in labeled_cells_j_c[j][c][1]:\n",
    "                    labeled_cells_j_c[j][c][1][cell] = (1,label)\n",
    "    return labeled_cells_j_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = propagate(d_test)\n",
    "lsc = {j: [] for j in range(d_test.dataframe.shape[1])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_heterogene_3(d,labeled_cells_j_c):\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    labeled_sub_cells_j_c = {j: [] for j in range(d.dataframe.shape[1])}\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in labeled_cells_j_c[j]:\n",
    "            if sum(labeled_cells_j_c[j][c][0].values()) not in [0,len(labeled_cells_j_c[j][c][0].values())]:\n",
    "                print(labeled_cells_j_c[j][c][0])\n",
    "                sub_cluster_train = [d.column_features[j][i] for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "                sub_cluster_cells = [(i,j) for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "                sub_cluster_labels = []\n",
    "                for i in range(d.dataframe.shape[0]):\n",
    "                    if (i,j) in labeled_cells_j_c[j][c][0]:\n",
    "                        sub_cluster_labels.append(labeled_cells_j_c[j][c][0][(i,j)])\n",
    "                    elif (i,j) in labeled_cells_j_c[j][c][1]:\n",
    "                        sub_cluster_labels.append(-1)\n",
    "                closest_labeled_point = []\n",
    "                sub_cluster_labeled_features = [sub_cluster_train[i] for i in range(len(sub_cluster_train)) if sub_cluster_cells[i] in labeled_cells_j_c[j][c][0]]\n",
    "                for feature in sub_cluster_train:\n",
    "                    min_val = get_distance(numpy.zeros(len(feature)),numpy.ones(len(feature)),\"normal\")\n",
    "                    for feature2 in sub_cluster_labeled_features:\n",
    "                        tmp = get_distance(feature,feature2,\"normal\")\n",
    "                        if tmp < min_val: min_val = tmp\n",
    "                    closest_labeled_point.append(min_val)\n",
    "                #print(closest_labeled_point)\n",
    "                \n",
    "                label_prop = LabelPropagation().fit(sub_cluster_train,sub_cluster_labels)\n",
    "                for i in range(len(sub_cluster_train)):\n",
    "                    if sub_cluster_cells[i] in labeled_cells_j_c[j][c][1]:\n",
    "                        labeled_cells_j_c[j][c][1][sub_cluster_cells[i]] = (max(label_prop.label_distributions_[i])*(0.9**closest_labeled_point[i]),label_prop.transduction_[i])\n",
    "                        #print(sub_cluster_cells[i],label_prop.transduction_[i],max(label_prop.label_distributions_[i])*(0.9**closest_labeled_point[i]))\n",
    "    return labeled_cells_j_c                                        \n",
    "lc = propagate_heterogene_3(d_test,lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_heterogene_2(d,labeled_cells_j_c):\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in labeled_cells_j_c[j]:\n",
    "            if sum(labeled_cells_j_c[j][c][0].values()) not in [0,len(labeled_cells_j_c[j][c][0].values())]:\n",
    "                print(labeled_cells_j_c[j][c][0])\n",
    "                for cell1 in labeled_cells_j_c[j][c][1]:\n",
    "                    mode = \"similarity\"\n",
    "                    if mode == \"distance\":\n",
    "                        min_val = (1,1) # (weight,label)\n",
    "                        for cell2 in labeled_cells_j_c[j][c][0]:\n",
    "                            distance = get_distance(d.column_features[j][cell1[0]],d.column_features[j][cell2[0]],\"euclidean\")\n",
    "                            if min_val[0] > distance: min_val = (distance,labeled_cells_j_c[j][c][0][cell2])\n",
    "                        labeled_cells_j_c[j][c][1][cell1] = (1-min_val[0],min_val[1])\n",
    "                    if mode == \"similarity\":\n",
    "                        max_val = (0,1)\n",
    "                        for cell2 in labeled_cells_j_c[j][c][0]:\n",
    "                            similarity = get_similarity(d.column_features[j][cell1[0]],d.column_features[j][cell2[0]],\"antidice\")\n",
    "                            if max_val[0] < similarity: max_val = (similarity,labeled_cells_j_c[j][c][0][cell2])\n",
    "                        labeled_cells_j_c[j][c][1][cell1] = max_val\n",
    "                #print(labeled_cells_j_c[j][c])\n",
    "    return labeled_cells_j_c\n",
    "lc = propagate_heterogene_2(d_test,lc)\n",
    "lsc = {j: [] for j in range(d_test.dataframe.shape[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weighted_features(d,labeled_cells_j_c):\n",
    "    #append weight to features\n",
    "    heterogene = False\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    detected_cells_dictionary = {}\n",
    "    extended_labeled_cells = {}\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in labeled_cells_j_c[j]:\n",
    "            if len(labeled_cells_j_c[j][c][0]) != 0:\n",
    "                extended_labeled_cells.update(labeled_cells_j_c[j][c][0])\n",
    "                if not heterogene and sum(d.labels_per_cluster[(j, c)].values()) in [0,len(d.labels_per_cluster[(j, c)].values())]:\n",
    "                    extended_labeled_cells.update(labeled_cells_j_c[j][c][1])\n",
    "                elif heterogene:\n",
    "                    extended_labeled_cells.update(labeled_cells_j_c[j][c][1])\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        feature_vectores = d.column_features[j]\n",
    "        x_train = [feature_vectores[i] for i in range(d.dataframe.shape[0]) if (i,j) in extended_labeled_cells]\n",
    "        y_train = [extended_labeled_cells[(i,j)][1] for i in range(d.dataframe.shape[0]) if (i,j) in extended_labeled_cells]\n",
    "        weights = [extended_labeled_cells[(i,j)][0] for i in range(d.dataframe.shape[0]) if (i,j) in extended_labeled_cells]\n",
    "        print(\"Len x:\",len(x_train))\n",
    "        if sum(y_train) == len(y_train):\n",
    "            y_pred = numpy.ones(d.dataframe.shape[0])\n",
    "        elif sum(y_train) == 0 or len(x_train[0]) == 0:\n",
    "            y_pred = numpy.zeros(d.dataframe.shape[0])\n",
    "        else:\n",
    "            classifier = \"GBC\"\n",
    "            if classifier == \"GNB\":\n",
    "                model = sklearn.naive_bayes.GaussianNB()\n",
    "            if classifier == \"LIR\":\n",
    "                model = sklearn.linear_model.LinearRegression()\n",
    "            if classifier == \"LGR\":\n",
    "                model = sklearn.linear_model.LogisticRegression()\n",
    "            if classifier == \"RFR\":\n",
    "                model = sklearn.ensemble.RandomForestRegressor()\n",
    "            if classifier == \"ABC\":\n",
    "                model = sklearn.ensemble.AdaBoostClassifier(n_estimators=50)\n",
    "            if classifier == \"GBC\":\n",
    "                model = sklearn.ensemble.GradientBoostingClassifier()\n",
    "            if classifier == \"SGDC\":\n",
    "                model = sklearn.linear_model.SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "            model.fit(x_train,y_train,sample_weight=weights)\n",
    "            y_pred = model.predict(d.column_features[j])\n",
    "        for i,y in enumerate(y_pred):\n",
    "            #print((i,j),y)\n",
    "            if (i in d.labeled_tuples and d.labeled_cells[(i,j)][0]) or (i not in d.labeled_tuples and y):\n",
    "                detected_cells_dictionary[(i,j)] = \"Just a dummy value\"\n",
    "    return detected_cells_dictionary\n",
    "    for cell in detected_cells_dictionary:\n",
    "        print(cell,detected_cells_dictionary[cell])\n",
    "#{cluster_i: [labeled_cells in cluster_i,rest in cluster_i]}\n",
    "detected_cells = predict_weighted_features(d_test,lc)\n",
    "data_test = raha.dataset.Dataset(data_dict_3)\n",
    "p,r,f = data_test.get_data_cleaning_evaluation(detected_cells)[:3]\n",
    "print(p,r,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_heterogene(d,labeled_cells_j_c):\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    DISCOUNT = 0.8\n",
    "    SUB_CLUSTER_SIZE = 20\n",
    "    labeled_sub_cells_j_c = {j: {} for j in range(d.dataframe.shape[1])}\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in labeled_cells_j_c[j]:\n",
    "            #print(c,d.clusters_k_j_c_ce[k][j][c])\n",
    "            if (sum(labeled_cells_j_c[j][c][0].values()) not in [0,len(labeled_cells_j_c[j][c][0].values())]) and len(labeled_cells_j_c[j][c][0].values()) != 0:\n",
    "                #heterogene\n",
    "                sub_cluster_train = [d.column_features[j][i] for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "                sub_cluster_cells = [(i,j) for i in range(d.dataframe.shape[0]) if (i,j) in d.clusters_k_j_c_ce[k][j][c]]\n",
    "                #test cluster size to get homogene sub cluster\n",
    "                for c_size in range(SUB_CLUSTER_SIZE-2):\n",
    "                    print(\"Iteration\",c_size)\n",
    "                    homogene = 0\n",
    "                    km = sklearn.cluster.KMeans(n_clusters=(c_size+2)).fit(sub_cluster_train)\n",
    "                    sub_cluster = {sub_c: [{},{}] for sub_c in range(c_size+2)}\n",
    "                    #sub cluster index 0 = labeled , 1 = else \n",
    "                    for i,cell in enumerate(sub_cluster_cells):\n",
    "                        if cell in labeled_cells_j_c[j][c][0]:\n",
    "                            sub_cluster[km.labels_[i]][0][cell] = labeled_cells_j_c[j][c][0][cell]\n",
    "                        else:\n",
    "                            sub_cluster[km.labels_[i]][1][cell] = labeled_cells_j_c[j][c][1][cell]\n",
    "                    #check of sub cluster labels are homogene (counts empty too)\n",
    "                    for sub_c in sub_cluster:\n",
    "                        print(sub_c,sub_cluster[sub_c][0].values())\n",
    "                        if sum(sub_cluster[sub_c][0].values()) in [0,len(sub_cluster[sub_c][0].values())]:\n",
    "                            homogene += 1\n",
    "                    if homogene == len(sub_cluster):\n",
    "                        #calc weights\n",
    "                        for sub_c in sub_cluster:\n",
    "                            if len(sub_cluster[sub_c][0]) != 0:\n",
    "                                for cell1 in sub_cluster[sub_c][1]:\n",
    "                                    mode = \"distance\"\n",
    "                                    if mode == \"distance\":\n",
    "                                        min_val = 1\n",
    "                                        for cell2 in sub_cluster[sub_c][0]:\n",
    "                                            distance = get_distance(d.column_features[j][cell1[0]],d.column_features[j][cell2[0]],\"euclidean\")\n",
    "                                            if min_val > distance: min_val = distance\n",
    "                                        sub_cluster[sub_c][1][cell1] = ((1-distance)*DISCOUNT,sub_cluster[sub_c][0][cell2])\n",
    "                                    if mode == \"similarity\":\n",
    "                                        max_val = 0\n",
    "                                        for cell2 in sub_cluster[sub_c][0]:\n",
    "                                            similarity = get_similarity(d.column_features[j][cell1[0]],d.column_features[j][cell2[0]],\"matching\")\n",
    "                                            if max_val < similarity: min_val = similarity\n",
    "                                        sub_cluster[sub_c][1][cell1] = (similarity*DISCOUNT,sub_cluster[sub_c][0][cell2])\n",
    "                        break\n",
    "                for sub_c in sub_cluster:\n",
    "                    for cell in sub_cluster[sub_c][1]:\n",
    "                        labeled_cells_j_c[j][c][1][cell] = sub_cluster[sub_c][1][cell]\n",
    "    #print(labeled_sub_cells_j_c)\n",
    "    return labeled_cells_j_c\n",
    "lsc = propagate_heterogene(d_test,lc)\n",
    "lsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_test(dd,lb):\n",
    "    det = raha.detection.Detection()\n",
    "    d = det.initialize_dataset(dd)\n",
    "    det.run_strategies(d)\n",
    "    det.generate_features(d)\n",
    "    det.build_clusters(d)\n",
    "    while len(d.labeled_tuples) < lb:\n",
    "        det.sample_tuple(d)\n",
    "        if d.has_ground_truth:\n",
    "            det.label_with_ground_truth(d)\n",
    "    het = 0\n",
    "    hom = 0\n",
    "    k = len(d.labeled_tuples) + 2 - 1\n",
    "    for j in range(d.dataframe.shape[1]):\n",
    "        for c in d.clusters_k_j_c_ce[k][j]:        \n",
    "            if len(d.labels_per_cluster[(j,c)].values()) != 0 and sum(d.labels_per_cluster[(j,c)].values()) in [0,len(d.labels_per_cluster[(j,c)].values())]:\n",
    "                hom += 1\n",
    "            elif len(d.labels_per_cluster[(j,c)].values()) != 0:\n",
    "                het += 1\n",
    "    return hom,het"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (0,0)\n",
    "t += (1,1)\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
